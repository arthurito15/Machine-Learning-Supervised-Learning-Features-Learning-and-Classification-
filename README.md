# ğŸ“Š Credit Scoring â€“ Machine Learning & Data Processing

Ce projet explore diffÃ©rentes techniques dâ€™**apprentissage supervisÃ©**, de **feature engineering**, de **sÃ©lection de variables**, et dâ€™**orchestration de pipelines** appliquÃ©es Ã  un dataset de *credit scoring*.  
Il inclut Ã©galement un traitement avancÃ© de donnÃ©es hÃ©tÃ©rogÃ¨nes et la crÃ©ation dâ€™une **API FastAPI**.

---

## ğŸ“ Contenu du projet

Le projet couvre les Ã©tapes suivantes :

### 1. Chargement et prÃ©paration des donnÃ©es
- Import du dataset `credit_scoring.csv`
- SÃ©paration des features et de la variable cible `Status`
- Analyse du dÃ©sÃ©quilibre des classes  
  > *Exemple du document : 72% positifs, 28% nÃ©gatifs.*

---

## ğŸ§  Apprentissage supervisÃ©

### 2. EntraÃ®nement et Ã©valuation de modÃ¨les
ModÃ¨les testÃ©s :
- Decision Tree (DT)
- KNN
- MLP (rÃ©seau de neurones)

RÃ©sultats initiaux (accuracy) :
- **DT : 0.773**
- **KNN : 0.748**
- **MLP : 0.747**

Les courbes ROC montrent des performances comparables, avec un lÃ©ger avantage pour lâ€™arbre de dÃ©cision.

---

## ğŸ”§ Feature Engineering

### 3. Normalisation des variables continues
AprÃ¨s normalisation :
- **MLP devient le meilleur modÃ¨le (0.808)**  
- KNN et DT progressent Ã©galement

### 4. CrÃ©ation de nouvelles variables (combinaisons linÃ©aires)
Ajout de composantes PCA :
- LÃ©gÃ¨re amÃ©lioration globale
- Le MLP reste le plus performant sur donnÃ©es normalisÃ©es + PCA

---

## ğŸ† SÃ©lection de variables

### 5. Importance des variables & sÃ©lection optimale
MÃ©thode utilisÃ©e : Ã©limination itÃ©rative + MLP

Variables les plus importantes :
- Income  
- Seniority  
- pca2  
- pca3  
- Price  
- pca1  

> *Les 6 premiÃ¨res variables donnent la meilleure accuracy.*

Visualisations :
- Graphique dâ€™importance des variables
- Courbe accuracy vs nombre de variables
- Analyse SHAP (interactions entre Seniority et Home)

---

## âš™ï¸ Optimisation des modÃ¨les

### 6. Recherche dâ€™hyperparamÃ¨tres
Exemple :  
```
MLP â†’ hidden_layer_sizes = [46, 26]
```

---

## ğŸ§µ Pipelines & Orchestration

### 7. CrÃ©ation dâ€™un pipeline complet
Pipeline :
- StandardScaler  
- PCA  
- MLPClassifier  

### 8. Orchestration automatique
Fonction : `pipeline_generation_train_test_split`  
Permet dâ€™automatiser :
- SÃ©lection de variables  
- Normalisation  
- PCA  
- EntraÃ®nement du modÃ¨le optimal  

---

## ğŸŒ API FastAPI

### 9. DÃ©ploiement dâ€™une API
Le fichier `api.py` expose un endpoint permettant :
- De charger un modÃ¨le entraÃ®nÃ©
- De prÃ©dire le statut dâ€™un client Ã  partir de nouvelles donnÃ©es

---

# ğŸ”¬ Comparaison avancÃ©e dâ€™algorithmes

### 10. Tests sur plusieurs modÃ¨les
ModÃ¨les inclus :
- Naive Bayes
- CART / ID3 / Decision Stump
- MLP (20-10)
- KNN
- Bagging
- AdaBoost
- Random Forest
- Gradient Boosting

Tests rÃ©alisÃ©s sur :
- DonnÃ©es brutes  
- DonnÃ©es normalisÃ©es  
- DonnÃ©es normalisÃ©es + nouvelles variables  

### RÃ©sultats marquants :
- **AdaBoost, Random Forest et Gradient Boosting** sont les plus performants (â‰ˆ 0.79â€“0.80)
- Le MLP progresse fortement aprÃ¨s normalisation
- Les mÃ©thodes dâ€™ensemble (Bagging, Boosting) dominent globalement

---

# ğŸ§© DonnÃ©es hÃ©tÃ©rogÃ¨nes

## 1. Variables continues
- Nettoyage des donnÃ©es manquantes
- Normalisation
- Comparaison des modÃ¨les

## 2. Traitement des donnÃ©es manquantes
Techniques utilisÃ©es :
- Imputation moyenne (numÃ©rique)
- Imputation mode (catÃ©gorielle)
- One-Hot Encoding
- Standardisation

RÃ©sultats :
- Les modÃ¨les dâ€™ensemble restent les plus performants  
- **Bagging atteint 0.876**, meilleur score global

---

# ğŸš€ Installation & ExÃ©cution

### PrÃ©requis
```
Python 3.9+
pip install -r requirements.txt
```

### Lancer les notebooks
```
jupyter notebook
```

### Lancer lâ€™API FastAPI
```
uvicorn api:app --reload
```

---

# ğŸ“Œ Auteurs

- **Konkobo Ulrich Arthur**
- **Pellois Guillaume**
- **Issoumaila Fomba**

